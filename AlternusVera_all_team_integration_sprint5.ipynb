{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
<<<<<<< HEAD
    "accelerator": "GPU",
    "colab": {
      "name": "AlternusVera_all_team_integration_sprint5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fLx1PK9oogYU",
        "jbMdc5tLoT7p",
        "nUfbWvK2OBZ5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
=======
    "colab": {
      "name": "AlternusVera_all_team_integration_sprint5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ef7d0931ffa4e91b1bdb08fdd2cd506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_989e6fef9fb7414a93fd6847590583a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45506b945772478292c86e9fb95d6819",
              "IPY_MODEL_300bfeda48e548b2b22abb9e2e84c177"
            ]
          }
        },
        "989e6fef9fb7414a93fd6847590583a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45506b945772478292c86e9fb95d6819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69ae4898138041bba2b35581723cb227",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244715968,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244715968,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3d42d00af6940f8aed064a99e107160"
          }
        },
        "300bfeda48e548b2b22abb9e2e84c177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bca5bfa23cb644e28c71bf2049b9065b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 245M/245M [00:14&lt;00:00, 17.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d729eb5d6d6648b084c2b89d9fba24cf"
          }
        },
        "69ae4898138041bba2b35581723cb227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3d42d00af6940f8aed064a99e107160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bca5bfa23cb644e28c71bf2049b9065b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d729eb5d6d6648b084c2b89d9fba24cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< HEAD
=======
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jocelynbaduria/alternusvera-spring-2021/blob/main/AlternusVera_all_team_integration_sprint5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
        "id": "1ozZMQ-jqp0j"
      },
      "source": [
        "# CMPE 257 - MLSprings 2021 Cohort\n",
        "## Objective: Detect fake news in political datasets using factors\n",
        "\n",
        "## Factors by Team\n",
        "## Team Equality - Abhishek Bais, Haley Feng, Jimmy Liang, Shannon Phu\n",
        "### Abhishek - Misleading Intentions\n",
        "#### Microfactors:  \n",
        "Sentiment Analysis  \n",
        "Sensationalism  \n",
        "Click Bait \n",
        "\n",
        "Datasets:\n",
        "1. [Politifact](drive.google.com/file/d/1LUTnGJ1c8WDwcEmed85GhfoEUm2sJFzN/view)  \n",
        "2. [Amalgamated dataset from varied newsAPI feed](https://docs.google.com/spreadsheets/d/1jJflezhjlTPRoVHvj7UvQwllssq66zhZNPz7GI_Zwhc/edit#gid=22382224)  \n",
        "3. [Sensational words corpus](https://drive.google.com/file/d/1JIes9QhZw7EUt59EBDUgrdFMokoT1W8u/view)  \n",
        "\n",
        "### Shannon - Stance Detection\n",
        "#### Microfactors:  \n",
        "Sentiment Analysis  \n",
        "Subjectivity Score  \n",
        "BERT Embeddings  \n",
        "\n",
        "Datasets:\n",
        "1. [Fake News Challenge](https://www.kaggle.com/c/fakenewskdd2020)  \n",
        "2. [Politifact](drive.google.com/file/d/1LUTnGJ1c8WDwcEmed85GhfoEUm2sJFzN/view)  \n",
        "3. [Sentiment words corpus](https://drive.google.com/file/d/1JIes9QhZw7EUt59EBDUgrdFMokoT1W8u/view)  \n",
        "\n",
        "### Haley - Political Bias\n",
        "#### Microfactors: \n",
        "Sentiment Analysis  \n",
        "Party Affiliation  \n",
        "Vocab Selection Bias  \n",
        "1. Politifact\n",
        "2. [GoogleNews API](https://docs.google.com/spreadsheets/d/1Uu-266Q0ab88fnnjtrZ8MMMV8KGNzGoiGKXbBssza2s/edit?usp=sharing)\n",
        "3. [Ideological Book Corpus](https://people.cs.umass.edu/~miyyer/ibc/index.html) / [Kaggle Tweets](https://docs.google.com/spreadsheets/d/14KRtIdMqbp1Tnd7AraR-ROtPDTSQgc--hMmm0L7baDc/edit?usp=sharing)\n",
        "\n",
        "### Jimmy - Naive Realism\n",
        "#### Microfactors:  \n",
        "Topic Centrality  \n",
        "Polarization  \n",
        "Source Centrality  \n",
        "\n",
        "## Team DataCorps - Yuxing Wang, Arun Talkad, Mayuri Lalwani\n",
        "\n",
        "### Yuxing - Psychology Utilities\n",
        "#### Microfactors:\n",
        "Group confirmation<br />\n",
        "Opinion leader<br />\n",
        "Sentiment<br />\n",
        "Datasets:\n",
        "1. Politifact\n",
        "2. Twitter API\n",
        "3. News API\n",
        "\n",
        "### Mayuri - Intent\n",
        "#### Microfactors:\n",
        "Utterance<br />\n",
        "Speech<br />\n",
        "Sentiment<br />\n",
        "Datasets:\n",
        "1. politifact\n",
        "2. twitter\n",
        "3. newsapi\n",
        "\n",
        "### Arun - Source Reputation, Source Reliability\n",
        "#### Microfactors:\n",
        "Provenance Analysis <br />\n",
        "News Subjectivity   <br />             \n",
        "News Credibility  <br />              \n",
        "News Veracity Detection <br />\n",
        "Datasets:\n",
        "1. Politifact\n",
        "2. Twitter API\n",
        "3. News API <br />\n",
        "\n",
        "## Team Sparrow \n",
        "### Princy\n",
        "#### Microfactors\n",
        "Text similarity<br/>\n",
        "Sentiment Polarity <br/>\n",
        "Datasets:\n",
        "1. [Stance Dataset](http://www.fakenewschallenge.org)\n",
        "2. [ISOT Fake News Dataset\n",
        "](https://www.uvic.ca/engineering/ece/isot/datasets/fake-news/index.php)\n",
        "3. [Kaggle](https://www.kaggle.com/c/fake-news/)\n",
        "\n",
<<<<<<< HEAD
=======
        "\n",
        "### Samer\n",
        "#### Microfactors\n",
        "Named Entities <br/>\n",
        "Keyword Extraction <br/>\n",
        "Text Similarity <br/>\n",
        "\n",
        "Datasets:\n",
        "1. [ISOT Fake News Dataset]\n",
        "2. Politifact scraped dataset (from Kaggle by Shiv Ganesh)\n",
        "\n",
        "\n",
        "\n",
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
        "## Team Amalgam\n",
        "### Surabhi: Credibility\n",
        "#### Microfactors\n",
        "Author Experise<br />\n",
        "Content Credibility<br />\n",
        "Text Readability<br />\n",
        "Datasets Used: \n",
        "1. Scraped Data from Politifact website \n",
        "2. Scraped news article from web\n",
        "\n",
        "### Arpitha:  Style based approaches\n",
        "#### Microfactors\n",
        "Hyperpartisan<br />\n",
        "Yellow Journalism<br />\n",
        "Deception/Lying in text<br />\n",
        "Datasets Used: \n",
        "1. Kaggle fake news dataset: https://www.kaggle.com/surekharamireddy/fake-news-detection\n",
        "2. SemEval Hyperpartisan News Detection task dataset: https://pan.webis.de/semeval19/semeval19-web/\n",
        "\n",
        "### Gayathri: Authenticity\n",
        "#### Microfactors\n",
        "Flesch Reading Ease Score<br />\n",
        "Polarity score<br />\n",
        "Subjectivity Score<br />\n",
        "Datasets Used: \n",
        "1. Scraped Data from Politifact website\n",
        "\n",
        "\n",
        "\n",
        "## Team Underdog \n",
<<<<<<< HEAD
        "### Jocelyn \n",
        "### Source Reputation\n",
        "#### Microfactors\n",
        "Source Ratings Score \n",
        "Reputation Score \n",
        "Sentence Similarity\n",
        "### Datasets used:\n",
        "1. Scraped Data from Politifact and FoxNews Website\n",
        "\n",
        "________\n",
        "## Team Musketeers\n",
        "### Raghava Devaraje Urs\n",
        "#### Microfactors\n",
        "**Political Affiliation**\n",
        "1. Sentiment analysis\n",
        "2. Party affiliations \n",
        "3. Click Bait\n",
        "\n",
        "### Kumuda Benakanahalli \n",
        "#### Microfactors\n",
        "**Spam**\n",
        "1. HAM WORD count\n",
        "2. SPAM WORD count \n",
        "3. Readability ease\n",
        "\n",
        "### Shiv Kumar Ganesh\n",
        "#### Microfactors\n",
        "**Writing Style**\n",
        "1. Vocab Analysis\n",
        "2. Lexical Analysis\n",
        "3. Readibility Analysis\n",
        "_____\n",
        "## Team ml-coders\n",
        "###  \n",
        "#### Microfactors\n",
        "1. Sentiment Intensity\n",
        "2. Political Bias\n",
        "3. Readability Score\n",
        "1. Clickbait\n",
        "2. Toxicity\n",
        "3. Subjectivity\n",
        "4. Sentiment Polarity\n",
        "1. Sensatonalism\n",
        "2. Linguistic Bias\n",
        "3. Vagnuess\n",
        "1. Sentiment Analysis\n",
        "2. Readibility Analysis\n",
        "\n",
        "\n",
        "_____"
=======
        "### Jocelyn: Source Reputation\n",
        "#### Microfactors\n",
        "Source Ratings Score <br />\n",
        "Reputation Score <br />\n",
        "Sentence Similarity <br />\n",
        "### Weifeng: Reliable Source \n",
        "#### Microfactors\n",
        "Context Veracity <br />\n",
        "Commom linguistic <br />\n",
        "Reliabilty value of source <br />\n",
        "### Bhuvana: Reliable Source \n",
        "#### Microfactors\n",
        "Sentiment score <br />\n",
        "Sentence Format Score <br />\n",
        "Flesch-Kincaid Score <br />\n",
        "\n",
        "### Datasets used:\n",
        "1. [Scraped Data](https://www.politifact.com/factchecks/list/?ruling)\n",
        "2. Scraped headlines from New York Post, Washington Post, Buzzfeed News on 04-19-2021\n",
        "3. [Kaggle](https://www.kaggle.com/amananandrai/clickbait-dataset)\n",
        "4. Inference - Scrape real-time data from Foxnews \n",
        "\n",
        "## Team Data Divers\n",
        "### Anirudh: Malicious Account\n",
        "#### Microfactors\n",
        "content similarity<br />\n",
        "sentiment<br />\n",
        "text stat<br />\n",
        "### Datasets used:\n",
        "\n",
        "### Riddhi: Credibility and Reliability\n",
        "#### Microfactors\n",
        "Credibility of Author<br />\n",
        "Content Quality<br />\n",
        "Subjectivity<br />\n",
        "### Datasets used:\n",
        "\n",
        "### Somya: Sensationalism\n",
        "#### Microfactors\n",
        "Clickbait<br />\n",
        "Sentiment Analysis<br />\n",
        "Use of sensationalist words<br />\n",
        "### Datasets used:\n",
        "\n",
        "### Sheema: Long Term Utility\n",
        "#### Microfactors\n",
        "Reputation<br />\n",
        "Credibility<br />\n",
        "Authenticity<br />\n",
        "### Datasets used:"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C4abpQqjAj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "outputId": "fdbfe09f-2f99-403e-8a90-4624b91e96a3"
=======
        "outputId": "0c017997-8c9c-49d2-d5b0-1424962b616c"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      },
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install transformers"
      ],
<<<<<<< HEAD

      "execution_count": 1,

=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
=======
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/87/49dc49e13ac107ce912c2f3f3fd92252c6d4221e88d1e6c16747044a11d8/sentence-transformers-1.1.0.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-cp37-none-any.whl size=119615 sha256=1ebc2b29d6b4a26bbeecf783b3ec03fc7dbd427640e87d4388a01c653d45f080\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/cb/21/1066bff3027215c760ca14a198f698bca8fccb92e33e2327eb\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.45 sentence-transformers-1.1.0 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt6Ge7dNq29P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "outputId": "633f6b56-42c3-43da-9ceb-7a567f4e1800"
=======
        "outputId": "544fa3ca-cadc-44e5-a4da-594bc80b0a9a"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      },
      "source": [
        "# Import standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import pickle\n",
        "import nltk\n",
        "from transformers import pipeline\n",
        "nltk.download('punkt')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.corpus import stopwords\n",
<<<<<<< HEAD
        "nltk.download('stopwords')"
      ],

      "execution_count": 2,
=======
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "from nltk import ne_chunk, pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tree import Tree\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.util import ngrams\n"
      ],
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
<<<<<<< HEAD
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
=======
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6JXxaedfOj7"
      },
      "source": [
        "!pip install -U -q pyDrive"
      ],
<<<<<<< HEAD
      "execution_count": 3,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWqJQotGeV6b"
      },
      "source": [
        "# Import packages for google drive, auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "gdrive = GoogleDrive(gauth)"
      ],
<<<<<<< HEAD
      "execution_count": 4,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvzcys0ueBkd"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from textblob import TextBlob\n",
        "from sentence_transformers import SentenceTransformer"
      ],
<<<<<<< HEAD
      "execution_count": 5,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noSA0zB6nzwJ"
      },
      "source": [
        "# 1.0. Read in streaming news headlines\n",
        "\n",
        "a. Streaming news headlines are from https://newsapi.org/  \n",
        "c. Streaming news headlines are from CNN, Brietbart News and Fox News 2021/4/25 - 2021/4/26"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEdR7Valn_H2",
        "colab": {
          "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
          "height": 742
        },
        "outputId": "4271defd-f91a-4454-b745-71b88d5ab37b"
=======
          "height": 417
        },
        "outputId": "16d0f944-f89b-4136-ffc4-3a667bc08035"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      },
      "source": [
        "r = requests.get('https://docs.google.com/spreadsheets/d/e/2PACX-1vQoXVHhfQlxAlQ8b3eHot7dDhXmCYM9iYC7i0mZMMpzwejhvCjMeEEHPTRhI7KCqOkRbmHBfsxKp0gw/pub?gid=1486725861&single=true&output=tsv')\n",
        "data = r.content\n",
        "df_test_headlines = pd.read_csv(BytesIO(data), sep='\\t')\n",
        "df_test_headlines"
      ],
<<<<<<< HEAD
      "execution_count": 6,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>body</th>\n",
              "      <th>source</th>\n",
              "      <th>preprocessed_statement_text</th>\n",
              "      <th>preprocessed_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-04-26T23:59:00Z</td>\n",
              "      <td>India is spiraling deeper into Covid-19 crisis...</td>\n",
              "      <td>India is experiencing the world's worst Covid-...</td>\n",
              "      <td>CNN</td>\n",
              "      <td>india spiral deeper covid crisi need know</td>\n",
              "      <td>india experienc world worst covid outbreak rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-04-26T23:52:26Z</td>\n",
              "      <td>New York to lose House seat -- and an Electora...</td>\n",
              "      <td>New York state came just 89 residents short of...</td>\n",
              "      <td>CNN</td>\n",
              "      <td>new york lose hous seat elector colleg vote fa...</td>\n",
              "      <td>new york state came resid short maintain congr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-04-26T23:29:09Z</td>\n",
              "      <td>Trump's effort to overturn loss becomes 2022 G...</td>\n",
              "      <td>Former North Carolina Gov. Pat McCrory acknowl...</td>\n",
              "      <td>CNN</td>\n",
              "      <td>trump effort overturn loss becom gop litmus te...</td>\n",
              "      <td>former north carolina gov pat mccrori acknowle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-04-26T23:27:31Z</td>\n",
              "      <td>Fox News host admits his show was wrong about ...</td>\n",
              "      <td>A Fox News anchor admitted on air on Monday th...</td>\n",
              "      <td>CNN</td>\n",
              "      <td>fox news host admit show wrong biden limit red...</td>\n",
              "      <td>fox news anchor admit air monday show inaccur ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-04-26T22:40:13Z</td>\n",
              "      <td>The Chauvin trial produced a new liberal icon</td>\n",
              "      <td>The conviction last week of former Minneapolis...</td>\n",
              "      <td>CNN</td>\n",
              "      <td>chauvin trial produc new liber icon</td>\n",
              "      <td>convict last week former minneapoli polic offi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>2021-04-26T16:57:43Z</td>\n",
              "      <td>Disney World is hiring in preparation for capa...</td>\n",
              "      <td>Things are apparently getting busier at Disney...</td>\n",
              "      <td>Fox News</td>\n",
              "      <td>disney world hire prepar capac increas report</td>\n",
              "      <td>thing appar get busier disney world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>2021-04-26T16:53:12Z</td>\n",
              "      <td>New York Times 'buried' bombshell that John Ke...</td>\n",
              "      <td>The New York Times is taking criticism for \"bu...</td>\n",
              "      <td>Fox News</td>\n",
              "      <td>new york time buri bombshel john kerri told ir...</td>\n",
              "      <td>new york time take critic buri report former s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>2021-04-26T16:39:50Z</td>\n",
              "      <td>Arizona's Flag Fire balloons in size, promptin...</td>\n",
              "      <td>The Flag Fire in Arizona has swelled to a dang...</td>\n",
              "      <td>Fox News</td>\n",
              "      <td>arizona flag fire balloon size prompt evacu</td>\n",
              "      <td>flag fire arizona swell danger level prompt of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>2021-04-26T16:36:44Z</td>\n",
              "      <td>Used pickup prices are skyrocketing amid new v...</td>\n",
              "      <td>A shortage of new vehicles has led to steep in...</td>\n",
              "      <td>Fox News</td>\n",
              "      <td>use pickup price skyrocket amid new vehicl sho...</td>\n",
              "      <td>shortag new vehicl led steep increas price use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>2021-04-26T16:31:52Z</td>\n",
              "      <td>Dubai sheikh still chasing elusive Kentucky De...</td>\n",
              "      <td>Winning major horse races around the world is ...</td>\n",
              "      <td>Fox News</td>\n",
              "      <td>dubai sheikh still chase elus kentucki derbi v...</td>\n",
              "      <td>win major hors race around world lifeblood god...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>299 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     date  ...                                  preprocessed_body\n",
              "0    2021-04-26T23:59:00Z  ...  india experienc world worst covid outbreak rec...\n",
              "1    2021-04-26T23:52:26Z  ...  new york state came resid short maintain congr...\n",
              "2    2021-04-26T23:29:09Z  ...  former north carolina gov pat mccrori acknowle...\n",
              "3    2021-04-26T23:27:31Z  ...  fox news anchor admit air monday show inaccur ...\n",
              "4    2021-04-26T22:40:13Z  ...  convict last week former minneapoli polic offi...\n",
              "..                    ...  ...                                                ...\n",
              "294  2021-04-26T16:57:43Z  ...                thing appar get busier disney world\n",
              "295  2021-04-26T16:53:12Z  ...  new york time take critic buri report former s...\n",
              "296  2021-04-26T16:39:50Z  ...  flag fire arizona swell danger level prompt of...\n",
              "297  2021-04-26T16:36:44Z  ...  shortag new vehicl led steep increas price use...\n",
              "298  2021-04-26T16:31:52Z  ...  win major hors race around world lifeblood god...\n",
              "\n",
              "[299 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I47CwebudtV2"
      },
      "source": [
        "# 2.0. Predict news headline is true/ false by ensembling factors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "timAm5UXdmqP"
      },
      "source": [
<<<<<<< HEAD
        "## 2.a. Define a false-o-meter\n",
=======
        "## 2.1. Define a false-o-meter\n",
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
        "1. Associate weights with each micro-factor proportional to model accuracy\n",
        "2. Probablity news is false is obtained by ensembling micro-factors as follows\n",
        "Define: A [false-o-meter] as s polynomial function f(p) = p0w0 + p1w1 + p2*w2\n",
        "where\n",
        "i. p is predicited probability of a micro-factor\n",
        "ii. w is normalized weight of micro-factors, proportional to accuracy of its prediction\n",
        "\n",
        "3. Labels news as follows based on false-o-meter f(p) reading\n",
        "i. Pants on Fire - if false-o-meter > 0.9\n",
        "ii. Somewhat False - if 0.7 < false-o-meter < 0.9\n",
        "iii. Mostly False - if 0.5 < false-o-meter < 0.7\n",
        "iv. Half True - if 0.3 < false-o-meter < 0.5\n",
        "v. Mostly True - if 0.1 < false-o-meter < 0.3\n",
        "vi. True - if 0.1 < false-o-meter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tj9YbF3u6u5"
      },
      "source": [
<<<<<<< HEAD
        "## 2.b. Define Stance Predictor"
=======
        "## 2.2. Define Stance Predictor"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKq470C2grOd"
      },
      "source": [
        "def apply_stance_detection_featurization(df_, sentiment_analyzer, headlineCol='Headline', bodyCol='ArticleBody'):\n",
        "  orig_cols = df_.copy().columns\n",
        "  df_['body_sentiment_score'] = df_[bodyCol].apply(lambda text: sentiment_analyzer.polarity_scores(text)['compound'])\n",
        "  df_['body_subjectivity_score'] = df_[bodyCol].apply(lambda text: TextBlob(text).sentiment[1])\n",
        "  df_['title_sentiment_score'] = df_[headlineCol].apply(lambda text: sentiment_analyzer.polarity_scores(text)['compound'])\n",
        "  df_['title_subjectivity_score'] = df_[headlineCol].apply(lambda text: TextBlob(text).sentiment[1])\n",
        "  df_ = df_.reset_index()\n",
        "\n",
        "  feature_names = ['body_sentiment_score', 'body_subjectivity_score', 'title_sentiment_score', 'title_subjectivity_score']\n",
        "  poly = PolynomialFeatures(interaction_only=True)\n",
        "  interaction_features = pd.DataFrame(poly.fit_transform(df_[feature_names].to_numpy()))\n",
        "  interaction_feature_names = poly.get_feature_names(input_features=feature_names)\n",
        "  interaction_features.columns = interaction_feature_names\n",
        "  interaction_features = interaction_features.drop(['1'], axis=1)\n",
        "  interaction_feature_names.remove('1')\n",
        "\n",
        "  headline_sentence_embeddings = pd.DataFrame(np.stack(df_[headlineCol].apply(transformer_model.encode).to_numpy()), columns=['heademb_{}'.format(i) for i in range(768)])\n",
        "  article_sentence_embeddings = pd.DataFrame(np.stack(df_[bodyCol].apply(transformer_model.encode).to_numpy()), columns=['artemb_{}'.format(i) for i in range(768)])\n",
        "\n",
        "  features = pd.concat([df_[orig_cols], interaction_features, headline_sentence_embeddings, article_sentence_embeddings], axis=1)\n",
        "  return features"
      ],
<<<<<<< HEAD
      "execution_count": 7,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "VQuyQVdbmd0F"
=======
        "id": "VQuyQVdbmd0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5ef7d0931ffa4e91b1bdb08fdd2cd506",
            "989e6fef9fb7414a93fd6847590583a2",
            "45506b945772478292c86e9fb95d6819",
            "300bfeda48e548b2b22abb9e2e84c177",
            "69ae4898138041bba2b35581723cb227",
            "e3d42d00af6940f8aed064a99e107160",
            "bca5bfa23cb644e28c71bf2049b9065b",
            "d729eb5d6d6648b084c2b89d9fba24cf"
          ]
        },
        "outputId": "c8ddfaab-101c-48f5-c75d-7badd604666c"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      },
      "source": [
        "file_id = '1DV5hmLvLJWYBviF6ps0nXV5FCu1URXyL'\n",
        "model_filename = 'stance_detection.pkl'\n",
        "downloaded = gdrive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile(model_filename)\n",
        "pickle_filepath = '/content/{}'.format(model_filename)\n",
        "stance_detection_model = pickle.load(open(pickle_filepath, 'rb'))\n",
        "\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "transformer_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
        "\n",
        "def getStancePrediction(X_headline, X_body):\n",
        "  prob = [0, 0, 0]\n",
        "  if X_headline.size == 1:\n",
        "    # prepare data for stance prediction\n",
        "    df = pd.DataFrame([(X_headline.iloc[0], X_body.iloc[0])], columns=['Headline', 'ArticleBody']) \n",
        "    stance_detection_features = apply_stance_detection_featurization(df, sentiment_analyzer, headlineCol='Headline', bodyCol='ArticleBody')\n",
        "    stance_detection_X = stance_detection_features.drop(['Headline', 'ArticleBody'], axis=1).to_numpy()\n",
        "    stance_detection_prediction_score = stance_detection_model.predict_proba(stance_detection_X)[0]\n",
        "    # make a prediction\n",
        "    prob = stance_detection_prediction_score\n",
        "\n",
        "  return prob"
      ],
<<<<<<< HEAD
      "execution_count": 8,
      "outputs": []
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ef7d0931ffa4e91b1bdb08fdd2cd506",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244715968.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoz_GwWEuyOK"
      },
      "source": [
<<<<<<< HEAD
        "## 2.c. Define Sentiment Predictor"
=======
        "## 2.3. Define Sentiment Predictor"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4qVLO1EdqH2"
      },
      "source": [
        "def getSentimentPrediction(X_news):\n",
        "  prob = 0\n",
        "  if X_news.size == 1:\n",
        "    file_id = '1eZ0TycVjHAyaFh8eKDmyLiQ_DN8rOcbI'\n",
        "    model_filename = 'Best_Sentiment_Analysis_Model_Misleading_Intentions.pkl'\n",
        "    downloaded = gdrive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(model_filename)\n",
        "    pickle_filepath = '/content/{}'.format(model_filename)\n",
        "    best_sentiment_model = pickle.load(open(pickle_filepath, 'rb'))\n",
        "    prob = best_sentiment_model.predict_proba(X_news)[:,1]\n",
        "  return float(prob)"
      ],
<<<<<<< HEAD
      "execution_count": 9,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x8PlEguu1s4"
      },
      "source": [
<<<<<<< HEAD
        "## 2.d. Define Sensationalism Predictor"
=======
        "## 2.4. Define Sensationalism Predictor"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_MZQd_90cvu"
      },
      "source": [
        "def getSensationalismPrediction(X_news):\n",
        "  prob = 0\n",
        "  if X_news.size == 1:\n",
        "    file_id = '1XEYOqUEkI52tW7ZWtIGRq0Qe5dOd2I_S'\n",
        "    model_filename = 'Best_Sensationalism_Analysis_Model_Misleading_Intentions.pkl'\n",
        "    downloaded = gdrive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(model_filename)\n",
        "    pickle_filepath = '/content/{}'.format(model_filename)\n",
        "    best_sensationalism_model = pickle.load(open(pickle_filepath, 'rb'))\n",
        "    prob = best_sensationalism_model.predict_proba(X_news)[:,1]\n",
        "  return float(prob)"
      ],
<<<<<<< HEAD
      "execution_count": 10,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoC7DQHSvDG6"
      },
      "source": [
<<<<<<< HEAD
        "## 2.e. Define ClickBait Predictor"
=======
        "## 2.5. Define ClickBait Predictor"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEEQtnWNd3Ic"
      },
      "source": [
        "def getDistilledClickBaitPrediction(X_news):\n",
        "  prob = 0\n",
        "  if X_news.size == 1:\n",
        "    file_id = '1pgSrMJD0m_7Cd1fg1xoZEN2P_CjnpUkb'\n",
        "    model_filename = 'Best_Clickbait_Analysis_Model_Misleading_Intentions.pkl'\n",
        "    downloaded = gdrive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(model_filename)\n",
        "    pickle_filepath = '/content/{}'.format(model_filename)\n",
        "    best_distilled_clickbait_model = pickle.load(open(pickle_filepath, 'rb'))\n",
        "    prob = best_distilled_clickbait_model.predict_proba(X_news)[:,1]\n",
        "  return float(prob)"
      ],
<<<<<<< HEAD
      "execution_count": 11,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7YJG4qERpqA"
      },
      "source": [
<<<<<<< HEAD
        "## 2.f. Define Political Bias\n",
=======
        "## 2.6. Define Political Bias\n",
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ_fD6l_R2n9"
      },
      "source": [
        "def get_BSF(df): # Balance Sentiment Factor\n",
        "  if len(df) == 1:\n",
        "    df['BSF'] = df['Positive']/df['Negative']\n",
        "  else:\n",
        "    pos_mean = df['Positive'].mean()\n",
        "    neg_mean = df['Negative'].mean()\n",
        "    balance_sentiment = (abs(pos_mean - df['Positive'])+abs(neg_mean - df['Negative']))/2\n",
        "    df['BSF'] = balance_sentiment \n",
        "  return df\n",
        "\n",
        "# Microfactor 2\n",
        "def get_SPR(df): # Standardized Party Ratio\n",
        "  # Create a ratio to measure if text has a leniency towards a particular party\n",
        "  party_ratio = df['Democrat']/df['Republican']\n",
        "  # Standardized the ratio to make use of the overall mean and stand deviation\n",
        "  if len(df) == 1:\n",
        "    df['SPR'] = party_ratio\n",
        "  else:\n",
        "    df['SPR'] = abs(party_ratio - np.mean(party_ratio))/np.std(party_ratio)\n",
        "  return df\n",
        "\n",
        "# Microfactor 3\n",
        "def get_selection_bias(df, text_col=str): \n",
        "  clean_col_name = 'Cleaned_'+text_col\n",
        "  clean_text_token = df[text_col].apply(nltk.word_tokenize)\n",
        "\n",
        "  def count_bias_vocab(target, bias_list):\n",
        "    count = 0 \n",
        "    for vocab in bias_list:\n",
        "      if vocab in target:\n",
        "        count += 1\n",
        "    return count/len(bias_list)\n",
        "  \n",
        "  file_id = '15DBBkgI0TVfciwwhDptWoblvhIHGKmq9'\n",
        "  model_filename = 'vocab_selection.pkl'\n",
        "  downloaded = gdrive.CreateFile({'id': file_id})\n",
        "  downloaded.GetContentFile(model_filename)\n",
        "  pickle_filepath = '/content/{}'.format(model_filename)\n",
        "  vocab_selection = pickle.load(open(pickle_filepath, 'rb'))\n",
        "\n",
        "  lib_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['liberal'])\n",
        "  con_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['conservative'])\n",
        "  dem_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['democrat'])\n",
        "  rep_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['republican'])\n",
        "\n",
        "  # Create two new feature\n",
        "  # Weight more on liberal and conservative vocabs\n",
        "  df['Dem_Vocab_Freq'] = 0.6*lib_vocab_rate+0.4*dem_vocab_rate\n",
        "  df['Rep_Vocab_Freq'] = 0.6*con_vocab_rate+0.4*rep_vocab_rate\n",
        "  # Create a selection bias feature\n",
        "  df['Selection_Bias'] = df[[\"Dem_Vocab_Freq\", \"Rep_Vocab_Freq\"]].max(axis=1)\n",
        "  return df\n",
        "\n",
        "# Combine all microfactors\n",
        "def get_political_bias(df):\n",
        "  # Microfactor final calculation\n",
        "  if len(df) == 1:\n",
        "    BSF_diff = df['BSF']\n",
        "    SPR_diff = df['SPR']\n",
        "  else:\n",
        "    BSF_diff = abs(df['BSF'].mean() - df['BSF'])\n",
        "    BSF_diff = (BSF_diff-min(BSF_diff))/(max(BSF_diff)-min(BSF_diff))\n",
        "    SPR_diff = abs(df['SPR'].mean() - df['SPR'])\n",
        "    SPR_diff = (SPR_diff-min(SPR_diff))/(max(SPR_diff)-min(SPR_diff))\n",
        "  # Combine all the microfactors together\n",
        "  political_bias = (0.2*BSF_diff+0.2*SPR_diff+0.2*(1-df['Neutral'])+0.4*df['Selection_Bias'])\n",
        "  df['Political_Bias'] = political_bias\n",
        "  return df"
      ],
<<<<<<< HEAD
      "execution_count": 12,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h046_6ZUkrtn"
      },
      "source": [
        "To save time on loading zero shot model and create microfactors based on overall dataframe statistics, feature generation process (zero_shot_microfactors) is added in data prep notebook "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWHV-rlDSBij"
      },
      "source": [
        "def polit_bias_pipeline(df, clean_text_col=str):\n",
        "  #df = zero_shot_microfactor(df, text_col) \n",
        "  df = get_BSF(df)\n",
        "  df = get_SPR(df)\n",
        "  df = get_selection_bias(df, clean_text_col)\n",
        "  df = get_political_bias(df)\n",
        "  return df, df['Political_Bias']"
      ],
<<<<<<< HEAD
      "execution_count": 13,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLx1PK9oogYU"
      },
      "source": [
<<<<<<< HEAD
        "## 2.g. Title-Body Similarity Predictor"
=======
        "## 2.7. Title-Body Similarity Predictor"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z5hxsa5oyNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "outputId": "61e3e42c-14e3-4f7a-d2da-4cf7b2c52280"
=======
        "outputId": "f93fc772-0982-4d66-eb31-e6da5b65c39c"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      },
      "source": [
        "!pip install nltk==3.4 --quiet\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from scipy.sparse import vstack\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def cnt_sentences(df):\n",
        "  df['cnt_title_sentences'] = df['clean_title'].apply(lambda x: len(sent_tokenize(x)))\n",
        "  df['cnt_text_sentences'] = df['clean_body'].apply(lambda x: len(sent_tokenize(x)))\n",
        "\n",
        "def ngram(text, n):\n",
        "    n_grams = ngrams(word_tokenize(text), n)\n",
        "    return [ '_'.join(grams) for grams in n_grams]\n",
        "\n",
        "# Uni, Bi, Tri grams to get common word count features\n",
        "def generate_ngrams(df):\n",
        "  df[\"title_uni\"] = df[\"clean_title\"].map(lambda x: ngram(x, 1))\n",
        "  df[\"body_uni\"] = df[\"clean_body\"].map(lambda x: ngram(x, 1))\n",
        "  df[\"cnt_title_uni\"] = list(df.apply(lambda x: len(x['title_uni']), axis=1))\n",
        "  df[\"cnt_body_uni\"] = list(df.apply(lambda x: len(x['body_uni']), axis=1))\n",
        "  df[\"unq_cnt_title_uni\"] = list(df.apply(lambda x: len(set(x['title_uni'])), axis=1))\n",
        "  df[\"unq_cnt_body_uni\"] = list(df.apply(lambda x: len(set(x['body_uni'])), axis=1))\n",
        "\n",
        "  df[\"title_bi\"] = df[\"clean_title\"].map(lambda x: ngram(x, 2))\n",
        "  df[\"body_bi\"] = df[\"clean_body\"].map(lambda x: ngram(x, 2))\n",
        "  df[\"cnt_title_bi\"] = list(df.apply(lambda x: len(x['title_bi']), axis=1))\n",
        "  df[\"cnt_body_bi\"] = list(df.apply(lambda x: len(x['body_bi']), axis=1))\n",
        "  df[\"unq_cnt_title_bi\"] = list(df.apply(lambda x: len(set(x['title_bi'])), axis=1))\n",
        "  df[\"unq_cnt_body_bi\"] = list(df.apply(lambda x: len(set(x['body_bi'])), axis=1))\n",
        "\n",
        "  df[\"title_tri\"] = df[\"clean_title\"].map(lambda x: ngram(x, 3))\n",
        "  df[\"body_tri\"] = df[\"clean_body\"].map(lambda x: ngram(x, 3))\n",
        "  df[\"cnt_title_tri\"] = list(df.apply(lambda x: len(x['title_tri']), axis=1))\n",
        "  df[\"cnt_body_tri\"] = list(df.apply(lambda x: len(x['body_tri']), axis=1))\n",
        "  df[\"unq_cnt_title_tri\"] = list(df.apply(lambda x: len(set(x['title_tri'])), axis=1))\n",
        "  df[\"unq_cnt_body_tri\"] = list(df.apply(lambda x: len(set(x['body_tri'])), axis=1))\n",
        "\n",
        "def common_ngrams_in_body(df):\n",
        "  df[\"cnt_title_unis_in_body\"] =  list(df.apply(lambda x: sum([1. for w in x['title_uni'] if w in set(x['body_uni'])]), axis=1))\n",
        "  df[\"cnt_title_bis_in_body\"] =  list(df.apply(lambda x: sum([1. for w in x['title_bi'] if w in set(x['body_bi'])]), axis=1))\n",
        "  df[\"cnt_title_tris_in_body\"] =  list(df.apply(lambda x: sum([1. for w in x['title_tri'] if w in set(x['body_tri'])]), axis=1))\n",
        "\n",
        "def concat_title_body(df):\n",
        "  df['clean_title_body'] = df['clean_title'] + ' ' + df['clean_body']\n",
        "\n",
        "def tf_idf(df):\n",
        "  concat_title_body(df)\n",
        "  combined_vectors = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=1, use_idf=True, smooth_idf=True)\n",
        "  combined_vectors.fit(df[\"clean_title_body\"])\n",
        "  combined_vectors_dictionary = combined_vectors.vocabulary_\n",
        "  title_vectors = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=1, use_idf=True, smooth_idf=True, vocabulary=combined_vectors_dictionary)\n",
        "  title_tfidf_vectors = title_vectors.fit_transform(df['clean_title'])\n",
        "  text_vectors = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=1, use_idf=True, smooth_idf=True, vocabulary=combined_vectors_dictionary)\n",
        "  text_tfidf_vectors = text_vectors.fit_transform(df['clean_body'])\n",
        "  return title_tfidf_vectors, text_tfidf_vectors\n",
        "\n",
        "def similarity_score(df, title_vectors, text_vectors):\n",
        "  similarity_score = []\n",
        "  for i in range(len(df)):\n",
        "      similarity_score.append(1 - cosine(title_vectors[i], text_vectors[i]))\n",
        "  return similarity_score\n",
        "\n",
        "def tf_idf_similarity(df):\n",
        "  title_tfidf_vectors, text_tfidf_vectors = tf_idf(df)\n",
        "  df['similarity_title_body'] = similarity_score(df, title_tfidf_vectors.toarray(), text_tfidf_vectors.toarray())\n",
        "  return title_tfidf_vectors, text_tfidf_vectors\n",
        "\n",
        "def svd(data, title_tfidf_vectors, text_tfidf_vectors):\n",
        "  truncated_svd = TruncatedSVD(n_components=2, n_iter=10)\n",
        "  combined_vectors = vstack([title_tfidf_vectors, text_tfidf_vectors])\n",
        "  truncated_svd.fit(combined_vectors)\n",
        "  title_svd = truncated_svd.transform(title_tfidf_vectors)\n",
        "  text_svd = truncated_svd.transform(text_tfidf_vectors)\n",
        "  return title_svd, text_svd\n",
        "\n",
        "def topic_similarity(data, title_tfidf_vectors, text_tfidf_vectors):\n",
        "  title_svd_vectors, text_svd_vectors = svd(data, title_tfidf_vectors, text_tfidf_vectors)\n",
        "  data['topics_similarity_title_body'] = similarity_score(data, title_svd_vectors, text_svd_vectors)\n",
        "\n",
        "def get_distilled_dataset(title, text):\n",
        "  data = {'clean_title': [title.iloc[0]], 'clean_body': [text.iloc[0]]}\n",
        "  df_test = pd.DataFrame(data)\n",
        "  cnt_sentences(df_test)\n",
        "  generate_ngrams(df_test)\n",
        "  common_ngrams_in_body(df_test)\n",
        "  title_tfidf_vectors, text_tfidf_vectors = tf_idf_similarity(df_test)\n",
        "  topic_similarity(df_test, title_tfidf_vectors, text_tfidf_vectors)\n",
        "  X_cols = [x for i,x in enumerate(features) if x!='label']\n",
        "  return df_test[X_cols]\n",
        "\n",
        "features =     ['label',  'cnt_title_uni', 'cnt_body_uni',\n",
        "                'unq_cnt_title_uni', 'unq_cnt_body_uni', 'cnt_title_bi', 'cnt_body_bi',\n",
        "                'unq_cnt_title_bi', 'unq_cnt_body_bi', 'cnt_title_tri', 'cnt_body_tri',\n",
        "                'unq_cnt_title_tri', 'unq_cnt_body_tri', 'cnt_title_unis_in_body', \n",
        "                'cnt_title_bis_in_body', 'cnt_title_tris_in_body', 'similarity_title_body',\n",
        "                'topics_similarity_title_body',\n",
        "                ]\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(['agree', 'disagree', 'discuss', 'unrelated'])\n",
        "dict(zip(le.classes_, le.transform(le.classes_)))"
      ],
<<<<<<< HEAD
      "execution_count": 14,
      "outputs": [
        {
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 29.9MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 34.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 31.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 27.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 21.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 22.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 23.3MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 21.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 21.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 21.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 21.9MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 21.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 21.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 21.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 21.9MB/s eta 0:00:01\r\u001b[K     |████                            | 174kB 21.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184kB 21.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194kB 21.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204kB 21.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 266kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 348kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 460kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 471kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 481kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 501kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 512kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 522kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 532kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 604kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 614kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 634kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 645kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 655kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 665kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 686kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 696kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 706kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 768kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 778kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 788kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 798kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 808kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 819kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 829kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 839kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 860kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 870kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 880kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 890kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 901kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 911kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 921kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 931kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 942kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 952kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 962kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 972kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 993kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.0MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 21.9MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXwY8Kgm1V0Q"
      },
      "source": [
        "def getTitleVsBodyPrediction(title, body):\n",
        "  file_id = '1bwvFThCwg6pgM99R6p7Ly7K5vXPwRj6q'\n",
        "  model_filename = 'title_body_similarity_model.pkl'\n",
        "  downloaded = gdrive.CreateFile({'id': file_id})\n",
        "  downloaded.GetContentFile(model_filename)\n",
        "  pickle_filepath = '/content/{}'.format(model_filename)\n",
        "  title_body_similarity_model = pickle.load(open(pickle_filepath, 'rb'))\n",
        "  df_test = get_distilled_dataset(title, body)\n",
        "  return title_body_similarity_model.predict(df_test), title_body_similarity_model.predict_proba(df_test)"
      ],
<<<<<<< HEAD
      "execution_count": 15,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< HEAD
        "id": "SkCoAfpDHtWX"
      },
      "source": [
        "#Define Spam Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq7TeYFFKCHl",
        "outputId": "b95d177b-f37a-4ede-9dbb-ac8c53aeb0a2"
      },
      "source": [
        "pip install textstat"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (from textstat) (0.10.0)\n"
          ],
          "name": "stdout"
        }
=======
        "id": "tzDMMKcam72G"
      },
      "source": [
        "## 2.8. NodeRank"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "BmydG_ZmHpYe"
      },
      "source": [
        "from joblib import dump,load\n",
        "def load_ham_model():\n",
        "  !cp '/content/drive/MyDrive/MLSpring-2021/TeamIntegration_MLSpring2021/models/Kumuda _SpamFactor/ham_vectorizer' -d /content/ham_vectorizer\n",
        "  ! cp  '/content/drive/MyDrive/MLSpring-2021/TeamIntegration_MLSpring2021/models/Kumuda _SpamFactor/ham_classifier.model' -d /content/ham_classifier.model\n",
        "  ham_classifier=load('/content/ham_classifier.model')\n",
        "  ham_vectorizer=load('/content/ham_vectorizer')\n",
        "  return ham_vectorizer,ham_classifier\n",
        "\n",
        "def load_spam_model():\n",
        "  !cp '/content/drive/MyDrive/MLSpring-2021/TeamIntegration_MLSpring2021/models/Kumuda _SpamFactor/spam_vectorizer' -d /content/spam_vectorizer\n",
        "  ! cp  '/content/drive/MyDrive/MLSpring-2021/TeamIntegration_MLSpring2021/models/Kumuda _SpamFactor/spam_classifier.model' -d /content/spam_classifier.model\n",
        "  spam_classifier=load('/content/spam_classifier.model')\n",
        "  spam_vectorizer=load('/content/spam_vectorizer')\n",
        "  return spam_vectorizer,spam_classifier"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u27PWskSH36E"
      },
      "source": [
        "ham_vectorizer,ham_classifier=load_ham_model()\n",
        "spam_vectorizer,spam_classifier=load_spam_model()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQIVVk-9H8zF"
      },
      "source": [
        "def calculate_ham_score(X_news):\n",
        "  X_train=ham_vectorizer.transform(X_news)\n",
        "  ham_score=ham_classifier.predict_proba(X_train)[:,1]\n",
        "  return float(ham_score[0])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A21RlQwhIEbv"
      },
      "source": [
        "def calculate_spam_score(X_news):\n",
        "  X_train=spam_vectorizer.transform(X_news)\n",
        "  spam_score=spam_classifier.predict_proba(X_train)[:,1]\n",
        "  return float(spam_score[0])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQ_i9ZbIB6T"
      },
      "source": [
        "def get_reading_ease(X_news):\n",
        "  reading_ease=0.0\n",
        "  reading_ease=X_news.apply(textstat.flesch_reading_ease)\n",
        "  return float(reading_ease)"
      ],
      "execution_count": 21,
=======
        "id": "0NuMnvgNnJNE"
      },
      "source": [
        "def get_continuous_chunks(text):\n",
        "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
        "    prev = None\n",
        "    continuous_chunk = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for i in chunked:\n",
        "        if type(i) == Tree:\n",
        "            current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
        "        elif current_chunk:\n",
        "            named_entity = \" \".join(current_chunk)\n",
        "            if named_entity not in continuous_chunk:\n",
        "                continuous_chunk.append(named_entity)\n",
        "                current_chunk = []\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    return continuous_chunk\n",
        "\n",
        "def list_length(l):\n",
        "  return len(l)\n",
        "\n",
        "def cleaning(raw_news):\n",
        "    news = re.sub(\"[^a-zA-Z]\", \" \", str(raw_news)) # Remove sp chars and puncts\n",
        "    news =  news.lower()\n",
        "    news_words = nltk.word_tokenize(news)\n",
        "    stops = set(nltk.corpus.stopwords.words(\"english\")) # list to \"set\"\n",
        "    words = [w for w in  news_words  if not w in stops] # remove stopwords\n",
        "    lem = [WordNetLemmatizer().lemmatize(w) for w in words] # lemmatize\n",
        "    stems = [nltk.stem.SnowballStemmer('english').stem(w) for w in lem ] # stem\n",
        "    return \" \".join(stems) #join into one string separated by space\n",
        "\n",
        "def find_noderank(df, a, b):\n",
        "  noderank = b - a\n",
        "  df['noderank'] = noderank\n",
        "  return df\n",
        "\n",
        "def get_keywords(row):\n",
        "  text = row['source_quote']\n",
        "  lowered = text.lower()\n",
        "  tokens = nltk.tokenize.word_tokenize(lowered)\n",
        "  keywords = [keyword for keyword in tokens if keyword.isalpha() and not keyword in stop_words]\n",
        "  return keywords\n",
        "\n",
        "def apply_funcs(df):\n",
        "  df['named_entities'] = df['text'].apply(get_continuous_chunks)\n",
        "  df['number_of_entities'] = df['named_entities'].apply(list_length)\n",
        "  df['cleaned_text'] = df['text'].map(lambda x: cleaning(x))\n",
        "  df['cleaned_title'] = df['title'].map(lambda x: cleaning(x))\n",
        "  df['keywords'] = df.apply(get_keywords, axis = 1)\n",
        "  df['number_of_keywords'] = df['keywords'].apply(list_length)\n",
        "  count_sentences(df)\n",
        "  generate_ngram_features(df)\n",
        "  find_noderank(df, df.number_of_entities, df.number_of_keywords)"
      ],
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "U28pLtzPIHJU"
      },
      "source": [
        "import textstat\n",
        "def generateSpamScore(X_news):\n",
        "  accuracy = [0.4,0.4, 0.001]\n",
        "  w = [float(i)/sum(accuracy) for i in accuracy]\n",
        "  sumW = 0\n",
        "  prob = []\n",
        "  ham_score=calculate_ham_score(X_news)\n",
        "  prob.append(w[0] *(1- ham_score))#Ham Score\n",
        "  sumW =sumW + w[0]\n",
        "\n",
        "  spam_score=calculate_spam_score(X_news)\n",
        "  prob.append(w[1] * spam_score)#Spam Score\n",
        "  sumW += w[1]\n",
        "  prob.append(w[2] * get_reading_ease(X_news)) #Reading Ease\n",
        "  sumW += w[2]\n",
        "   \n",
        "  probTotal = sum(prob[0:len(prob)]) / sumW\n",
        "  return probTotal"
      ],
      "execution_count": 22,
=======
        "id": "ocY598SdnJLF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpAG3S6dvHc5"
      },
      "source": [
<<<<<<< HEAD
        "## 2.h. Define a false-o-meter"
=======
        "## 2.9. Define a false-o-meter"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ufpr5uDd5sE"
      },
      "source": [
        "# get false-o-meter reading of news item\n",
        "def get_false_o_meter_reading(df, index_num, x_news=str, x_body=str):\n",
        "    X_news = df[x_news]\n",
        "    X_body = df[x_body]\n",
<<<<<<< HEAD
        "    model_accuracy = [0.85, 0.73, 0.89, 0.92, 0.86, 0.97, 0.6, 0.7,0.83] \n",
=======
        "    model_accuracy = [0.85, 0.73, 0.89, 0.92, 0.86, 0.97, 0.6, 0.7] \n",
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
        "    model_weight = [acc/sum(model_accuracy) for acc in model_accuracy]\n",
        "    probablity_false_news = []\n",
        "\n",
        "    # get sentiment reading\n",
        "    sentiment_prob = getSentimentPrediction(X_news)\n",
        "    probablity_false_news.append(model_weight[0] * sentiment_prob)\n",
        "    print('Sentiment [false-o-meter] reading is %f ' %(sentiment_prob))\n",
        "\n",
        "    # get sensationalism reading\n",
        "    sensationalism_prob = getSensationalismPrediction(X_news)\n",
        "    probablity_false_news.append(model_weight[1] * sensationalism_prob)\n",
        "    print('Sensationalism [false-o-meter] reading is %f ' %(sensationalism_prob))\n",
        "\n",
        "    # get distilled clickbait reading\n",
        "    clickbait_prob = getDistilledClickBaitPrediction(X_news)\n",
        "    probablity_false_news.append(model_weight[2] * clickbait_prob)\n",
        "    print('Distilled Clickbait [false-o-meter] reading is %f ' %(clickbait_prob))\n",
        "\n",
        "    # get stance reading\n",
        "    (agree_stance_prob, disagree_stance_prob, neutral_stance_prob) = getStancePrediction(X_news, X_body)\n",
        "    probablity_false_news.append(model_weight[3] * agree_stance_prob) # agree stance\n",
        "    probablity_false_news.append(model_weight[4] * disagree_stance_prob) # disagree stance\n",
        "    probablity_false_news.append(model_weight[5] * neutral_stance_prob) # neutral stance\n",
        "    print('Stance [false-o-meter] reading is (agree: %f, disagree: %f, neutral: %f)' % (agree_stance_prob, disagree_stance_prob, neutral_stance_prob))\n",
        "\n",
        "    # get political bias\n",
        "    r = requests.get('https://docs.google.com/spreadsheets/d/e/2PACX-1vQd6WhaekUPRDxUIYXgx_zI_zAHodXl3__bfAnEa_GWT_eR9dVO55HALi_3jjnZmEwbZ_4YvUkG7Qtx/pub?gid=896471122&single=true&output=tsv')\n",
        "    data = r.content\n",
        "    zero_shot_microfactors = pd.read_csv(BytesIO(data), sep='\\t')\n",
        "    pb_df, political_bias_prob = polit_bias_pipeline(zero_shot_microfactors, x_news)\n",
        "    probablity_false_news.append(model_weight[6] * political_bias_prob.loc[index_num])\n",
        "    print('Political Bias [false-o-meter] reading is %f ' %(political_bias_prob.loc[index_num]))\n",
        "\n",
        "    # get title body similarity\n",
        "    title_body_pred, title_body_pred_prob = getTitleVsBodyPrediction(X_news, X_body)\n",
        "    t_b_fake_score = (title_body_pred_prob[0][1] * 0.6 + title_body_pred_prob[0][3] + 0.4)\n",
        "    probablity_false_news.append(model_weight[6] * t_b_fake_score)\n",
        "    print('Title-Body incongruence [false-o-meter] reading is %f ' %(t_b_fake_score))\n",
        "\n",
        "    # get distilled psychology utility reading\n",
        "    psychology_prob = getPsychologyUtilitiesPrediction(X_news)\n",
        "    probablity_false_news.append(model_weight[2] * psychology_prob)\n",
        "    print('Distilled Psychology Utility [false-o-meter] reading is %f ' %(psychology_prob))\n",
<<<<<<< HEAD
        "\n",
        "    # get distilled intent reading\n",
        "    intent_prob = getIntentPrediction(X_news)\n",
        "    probablity_false_news.append(model_weight[0] * intent_prob)\n",
        "    print('Distilled Intent [false-o-meter] reading is %f ' %(intent_prob))\n",
        "\n",
        "    # get spam score\n",
        "    spam_score= generateSpamScore(X_news)\n",
        "    probablity_false_news.append(model_weight[8] * spam_score)\n",
        "    print('Spam score is %f' %(spam_score))\n",
        "\n",
=======
        "  \n",
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
        "    cummalative_probablity_false_news = sum(probablity_false_news)\n",
        "    print('Ensembled [false-o-meter] reading is %f ' %(cummalative_probablity_false_news))\n",
        "\n",
        "    return cummalative_probablity_false_news"
      ],
<<<<<<< HEAD
      "execution_count": 23,
=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbMdc5tLoT7p"
      },
      "source": [
<<<<<<< HEAD
        "##2.i. Define Psychology Predictor"
=======
        "##2.10. Define Psychology Predictor"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A4Zueetoc7p"
      },
      "source": [
        "import string\n",
        "import joblib\n",
        "\n",
        "def get_text_processing(text):\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.append(['breaking', 'BREAKING'])\n",
        "  no_punctuation = [char for char in text if char not in string.punctuation]\n",
        "  no_punctuation = ''.join(no_punctuation)\n",
        "  return ' '.join([word for word in no_punctuation.split() if word.lower() not in stop_words])\n",
        "\n",
        "def getPsychologyUtilitiesPrediction(X_news):\n",
        "  prob = 0\n",
        "  X_news = X_news.apply(get_text_processing)\n",
        "  if X_news.size == 1:\n",
        "    file_id = '16egOQ8zTftur5jPFxfWTwYDTOOjdhQ6e'\n",
        "    model_filename = 'PsychologyUtilites_pipeline.pkl'\n",
        "    downloaded = gdrive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(model_filename)\n",
        "    pickle_filepath = '/content/{}'.format(model_filename)\n",
        "    best_distilled_psychology_model = joblib.load(open(pickle_filepath, 'rb'))\n",
        "    prob = best_distilled_psychology_model.predict(X_news)\n",
        "  return 1 if prob == 'Positive' else 0"
      ],
<<<<<<< HEAD

      "execution_count": 24,

=======
      "execution_count": null,
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< HEAD
        "id": "nUfbWvK2OBZ5"
      },
      "source": [
        "##2.j. Define Intent Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Iwlj7wOBZ7"
      },
      "source": [
        "def getIntentPrediction(X_news):\n",
        "  prob = 0\n",
        "  X_news = X_news.apply(get_text_processing)\n",
        "  if X_news.size == 1:\n",
        "    file_id = '1BFXgdw2MvJZl39CUx0jvfms1nzQI810j'\n",
        "    model_filename = 'Intent_pipeline.pkl'\n",
        "    downloaded = gdrive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(model_filename)\n",
        "    pickle_filepath = '/content/{}'.format(model_filename)\n",
        "    best_distilled_intent_model = joblib.load(open(pickle_filepath, 'rb'))\n",
        "    prob = best_distilled_intent_model.predict(X_news)\n",
        "  return 1 if prob == 'Positive' else 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8O68pYBvak0"
      },
      "source": [
        "# Data Divers"
      ]
=======
        "id": "2EHyXA9Zd-CM"
      },
      "source": [
        "# 3.0. Automated Inference Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnQh4rgCvSK4"
      },
      "source": [
        "## 3.1. Helper: Pick a random news item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sspSi0vxeQ04"
      },
      "source": [
        "def get_random_news_items(num_items):\n",
        "  random_news_items = df_test_headlines.sample(n=num_items)\n",
        "  return random_news_items"
      ],
      "execution_count": null,
      "outputs": []
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
    },
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< HEAD
        "id": "LX_gHXKyve2E"
      },
      "source": [
        "## Malicious account factor"
=======
        "id": "ZJ8H3Y9ceDhM"
      },
      "source": [
        "## 3.2. Helper:Print prediction of news item"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "U124XQQcvkNJ"
      },
      "source": [
        "from io import StringIO\n",
        "\n",
        "def read_from_drive(url):\n",
        "  file_id = url.split('/')[-2]\n",
        "  dwn_url='https://drive.google.com/uc?export=download&id=' + file_id\n",
        "  url = requests.get(dwn_url).content\n",
        "  raw = BytesIO(url)\n",
        "  return raw"
=======
        "id": "vXPuqpUyfGoN"
      },
      "source": [
        "def print_prediction(reading):\n",
        "  if reading > 0.9:\n",
        "    print (\"This news headline is: Pants on Fire\")\n",
        "  elif reading > 0.7 and reading < 0.9:\n",
        "    print (\"This news headline is: Somewhat False\")\n",
        "  elif reading > 0.5 and reading < 0.7:\n",
        "    print (\"This news headline is: Mostly False\")\n",
        "  elif reading > 0.3 and reading < 0.5:\n",
        "    print (\"This news headline is: Half True\")\n",
        "  elif reading > 0.1 and reading < 0.3:\n",
        "    print (\"This news headline is: Mostly True\")\n",
        "  elif reading < 0.1:\n",
        "    print (\"True\")  "
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ],
      "execution_count": null,
      "outputs": []
    },
    {
<<<<<<< HEAD
      "cell_type": "code",
      "metadata": {
        "id": "BYq2F_YLvlpJ"
      },
      "source": [
        "import textstat\n",
        "\n",
        "def get_textstat(text):\n",
        "  data = {'flesch_reading_ease':[textstat.flesch_reading_ease(text)],\n",
        "          'smog_index':[textstat.smog_index(text)],\n",
        "          'flesch_kincaid_grade':[textstat.flesch_kincaid_grade(text)],\n",
        "          'coleman_liau_index':[textstat.coleman_liau_index(text)],\n",
        "          'automated_readability_index':[textstat.automated_readability_index(text)],\n",
        "          'dale_chall_readability_score':[textstat.dale_chall_readability_score(text)],\n",
        "          'difficult_words':[textstat.difficult_words(text)],\n",
        "          'linsear_write_formula':[textstat.linsear_write_formula(text)],\n",
        "          'gunning_fog':[textstat.gunning_fog(text)],\n",
        "          'text_standard':[textstat.text_standard(text)],\n",
        "          'fernandez_huerta':[textstat.fernandez_huerta(text)]\n",
        "          }\n",
        "  return pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
=======
      "cell_type": "markdown",
      "metadata": {
        "id": "uqk1SUgEg_5k"
      },
      "source": [
        "## 3.3. Helper: Run automated pipeline"
      ]
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "1jHDlbFqvneD"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial import distance\n",
        "import statistics\n",
        "\n",
        "def cosine_sim(list):\n",
        "  if len(list) < 1:\n",
        "    return 0\n",
        "    \n",
        "  sims = []\n",
        "  tfidf_vectorizer = TfidfVectorizer()\n",
        "  matrix = tfidf_vectorizer.fit_transform(list)\n",
        "  matrix = matrix.toarray()\n",
        "  for i in range(0, matrix.shape[0]-1):\n",
        "      vect1 = matrix[i]\n",
        "      vect2 = matrix[i+1]\n",
        "      sims.append(distance.cosine(vect1, vect2))\n",
        "\n",
        "  if len(sims) > 0:\n",
        "    return statistics.mean(sims)\n",
        "  else:\n",
        "    return 0"
=======
        "id": "k1-VQtbUo69_"
      },
      "source": [
        "def run_automated_inference_pipeline(num_items):\n",
        "  X_headline = 'preprocessed_statement_text'\n",
        "  X_body = 'preprocessed_body'\n",
        "  random_news_items = get_random_news_items(num_items)\n",
        "\n",
        "  i = 0\n",
        "  while ( i < num_items):\n",
        "    news = random_news_items.sample(1)\n",
        "    print('\\nRunning [false-o-meter] on - %s ' % (news['text']))\n",
        "    reading = get_false_o_meter_reading(news, news.index[0], X_headline, X_body)\n",
        "    print('[false-o-meter] reading is %f ' %(reading))\n",
        "    print_prediction(reading)\n",
        "    i = i + 1"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ],
      "execution_count": null,
      "outputs": []
    },
    {
<<<<<<< HEAD
      "cell_type": "code",
      "metadata": {
        "id": "TdfIZu2zvo_r"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def sentiment_scores(sentence):\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "    return sentiment_dict['compound']"
      ],
      "execution_count": null,
      "outputs": []
=======
      "cell_type": "markdown",
      "metadata": {
        "id": "NRSFK3w0hUX7"
      },
      "source": [
        "## 3.4. Invoke automated pipeline on 20 random news items"
      ]
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "3EfK5Ljivqbz"
      },
      "source": [
        "def y_true(stream_data):\n",
        "  target_levels = []\n",
        "  target_levels_dict = {'true': 0, 'mostly-true': 1, 'half-true': 2, 'barely-true': 3, 'mostly-false': 3, 'false': 4, 'pants-fire': 5}\n",
        "  for target in stream_data['target']:\n",
        "    target_levels.append(target_levels_dict[target])\n",
        "  return target_levels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NhbO3nivr3r"
      },
      "source": [
        "import _pickle as cPickle\n",
        "\n",
        "m1_data = read_from_drive('https://drive.google.com/file/d/1-2zjFaaxznewERyTjj2QlKr_YvlklPls/view?usp=sharing')\n",
        "base_model = cPickle.loads(m1_data.getvalue())\n",
        "\n",
        "m2_data = read_from_drive('https://drive.google.com/file/d/1u7hSP6S7C1CgG_mpiSQbvL8TspHldKDp/view?usp=sharing')\n",
        "cosine_model = cPickle.loads(m2_data.getvalue())\n",
        "\n",
        "m3_data = read_from_drive('https://drive.google.com/file/d/1TPCW6Yf4XFRC1LQjs7tzC8ffzuRKQKAh/view?usp=sharing')\n",
        "sentiment_model = cPickle.loads(m3_data.getvalue())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puc1XrVZvtYB"
      },
      "source": [
        "def ensemble(newsList):\n",
        "  aggr_result = predict_feed(newsList, base_model, 0)*0.05 + predict_feed(newsList, cosine_model, 1)*0.9 + predict_feed(newsList, sentiment_model, 2)*0.05\n",
        "  # a = np.array(aggr_result) \n",
        "  # index = a.argmax()   \n",
        "  # return index\n",
        "  return aggr_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ5PGxcevu8W"
      },
      "source": [
        " def ma_prediction(data): \n",
        "  y_preds = np.zeros(shape=(data.shape[0], 6))\n",
        "  preds = data['preprocessed_body'].apply(ensemble)\n",
        "  for i in range(len(preds)):\n",
        "    y_preds[i,0] = preds.iloc[i][0][0]\n",
        "    y_preds[i,5] = preds.iloc[i][0][1]\n",
        "  return y_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzsl8737vwct"
      },
      "source": [
        "def predict_feed(news, model, f):\n",
        "  \n",
        "  reals = [news, news]\n",
        "  sentiment = sentiment_scores(news)\n",
        "  cosine = cosine_sim(reals)\n",
        "\n",
        "  test_feature = get_textstat(news)\n",
        "  test_feature.drop(['text_standard'], axis=1, inplace=True)\n",
        "  if f == 1:\n",
        "    test_feature['cosine_sim'] = cosine\n",
        "  if f == 2:\n",
        "    test_feature['sentiment_compound'] = sentiment\n",
        "\n",
        "  return model.predict_proba(test_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSsymfLcv4-G"
      },
      "source": [
        "## Credibility and Reliability Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFo9IZlHv80R"
      },
      "source": [
        "def read_csv_from_drive(url):\n",
        "  file_id = url.split('/')[-2]\n",
        "  dwn_url='https://drive.google.com/uc?export=download&id=' + file_id\n",
        "  url = requests.get(dwn_url).text\n",
        "  csv_raw = StringIO(url)\n",
        "  return pd.read_csv(csv_raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DneiFLVRv_3x"
      },
      "source": [
        "def load_amalgamated_dataset():\n",
        "  return read_csv_from_drive(\"https://drive.google.com/file/d/1BXS7P19YLErlXqCrUpIRsFXkODhTyrnG/view?usp=sharing\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkKGa68twDwe"
      },
      "source": [
        "def predict_mf_1_cred_of_author(tfidf_vectorizer, stream_test_dataset, politifact_amalgamated_dataset, df):\n",
        "  sparse_matrix_test = tfidf_vectorizer.transform(stream_test_dataset['preprocessed_statement_text'])\n",
        "  # OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
        "  doc_term_matrix_test = sparse_matrix_test.todense()\n",
        "  df_test = pd.DataFrame(doc_term_matrix_test, \n",
        "                      columns=tfidf_vectorizer.get_feature_names(), \n",
        "                      index=stream_test_dataset['preprocessed_statement_text'])\n",
        "  df_test\n",
        "  similarity_matrix = cosine_similarity(df_test, df)\n",
        "  true = []\n",
        "  mostly_true = []\n",
        "  barely_true = []\n",
        "  half_true = []\n",
        "  false = []\n",
        "  pants_fire = []\n",
        "  total_news = []\n",
        "  target_levels = []\n",
        "  credibility = []\n",
        "  for i in similarity_matrix:\n",
        "    #Got the highest similarity index for the article\n",
        "    maximum_val = i.argsort()[-1:][::-1]\n",
        "    true.append(politifact_amalgamated_dataset['true'][maximum_val[0]])\n",
        "    mostly_true.append(politifact_amalgamated_dataset['mostly_true'][maximum_val[0]])\n",
        "    barely_true.append(politifact_amalgamated_dataset['barely_true'][maximum_val[0]])\n",
        "    half_true.append(politifact_amalgamated_dataset['half_true'][maximum_val[0]])\n",
        "    false.append(politifact_amalgamated_dataset['false'][maximum_val[0]])\n",
        "    pants_fire.append(politifact_amalgamated_dataset['pants_fire'][maximum_val[0]])\n",
        "    total_news.append(politifact_amalgamated_dataset['total_news'][maximum_val[0]])\n",
        "    target_levels.append(politifact_amalgamated_dataset['target_level'][maximum_val[0]])\n",
        "    credibility.append(politifact_amalgamated_dataset['credibility'][maximum_val[0]])\n",
        "  stream_test_dataset['true'] = true\n",
        "  stream_test_dataset['mostly_true'] = mostly_true\n",
        "  stream_test_dataset['half_true'] = half_true\n",
        "  stream_test_dataset['barely_true'] = barely_true\n",
        "  stream_test_dataset['false'] = false\n",
        "  stream_test_dataset['pants_fire'] = pants_fire\n",
        "  stream_test_dataset['total_news'] = total_news\n",
        "  stream_test_dataset['target_level'] = target_levels\n",
        "  stream_test_dataset['credibility'] = credibility\n",
        "  return stream_test_dataset\n",
        "\n",
        "def predict_mf_2_content_quality(amalgamated_dataset, column_name):\n",
        "  flesh_scores = []\n",
        "  smog_indexes = []\n",
        "  flesch_kincaid_grades = []\n",
        "  coleman_liau_indexes = []\n",
        "  automated_readability_indexes = []\n",
        "  dale_chall_readability_scores = []\n",
        "  linsear_write_formulas = []\n",
        "  gunning_fogs = []\n",
        "  fernandez_huertas = []\n",
        "  for i in range(len(amalgamated_dataset)):\n",
        "    statement = amalgamated_dataset[column_name].iloc[i]\n",
        "\n",
        "    flesh_score = textstat.flesch_reading_ease(statement)\n",
        "    smog_index = textstat.smog_index(statement)\n",
        "    flesch_kincaid_grade = textstat.flesch_kincaid_grade(statement)\n",
        "    coleman_liau_index = textstat.coleman_liau_index(statement)\n",
        "    automated_readability_index = textstat.automated_readability_index(statement)\n",
        "    dale_chall_readability_score = textstat.dale_chall_readability_score(statement)\n",
        "    linsear_write_formula = textstat.linsear_write_formula(statement)\n",
        "    gunning_fog = textstat.gunning_fog(statement)\n",
        "    fernandez_huerta = textstat.fernandez_huerta(statement)\n",
        "\n",
        "\n",
        "\n",
        "    flesh_scores.append(flesh_score)\n",
        "    smog_indexes.append(smog_index)\n",
        "    flesch_kincaid_grades.append(flesch_kincaid_grade)\n",
        "    coleman_liau_indexes.append(coleman_liau_index)\n",
        "    automated_readability_indexes.append(automated_readability_index)\n",
        "    dale_chall_readability_scores.append(dale_chall_readability_score)\n",
        "    linsear_write_formulas.append(linsear_write_formula)\n",
        "    gunning_fogs.append(gunning_fog)\n",
        "    fernandez_huertas.append(fernandez_huerta)\n",
        "\n",
        "  amalgamated_dataset['flesh_scores'] = flesh_scores\n",
        "  amalgamated_dataset['smog_indexes'] = smog_indexes\n",
        "  amalgamated_dataset['flesch_kincaid_grades'] = flesch_kincaid_grades\n",
        "  amalgamated_dataset['coleman_liau_indexes'] = coleman_liau_indexes\n",
        "  amalgamated_dataset['automated_readability_indexes'] = automated_readability_indexes\n",
        "  amalgamated_dataset['dale_chall_readability_scores'] = dale_chall_readability_scores\n",
        "  amalgamated_dataset['linsear_write_formulas'] = linsear_write_formulas\n",
        "  amalgamated_dataset['gunning_fogs'] = gunning_fogs\n",
        "  amalgamated_dataset['fernandez_huertas'] = fernandez_huertas\n",
        "  return amalgamated_dataset\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "def get_sentences(text):\n",
        "    return re.split('\\? |, |!|\\n', text)\n",
        "\n",
        "def get_words(sentences):\n",
        "    return sum([sentence.split() for sentence in sentences], [])\n",
        "\n",
        "def get_average_word_length(words):\n",
        "    return sum([len(word) for word in words]) // len(words)\n",
        "  \n",
        "def get_average_word_based_sentence_length(sentences):\n",
        "    return sum([len(sentence.split()) for sentence in sentences]) // len(sentences)\n",
        "\n",
        "def get_average_chars_based_sentence_length(sentences):\n",
        "    return sum([len(sentence) for sentence in sentences]) // len(sentences)\n",
        "  \n",
        "def get_punctuations_count(text):\n",
        "    return len([c for c in text if c in string.punctuation])\n",
        "\n",
        "\n",
        "def predict_mf_3_subjectivity(dataset):\n",
        "  polarities = []\n",
        "  subjectivities = []\n",
        "  avg_word_len = []\n",
        "  avg_words_based_sen_len = []\n",
        "  avg_chars_based_sen_len = []\n",
        "  pun_count = []\n",
        "  for title in dataset['preprocessed_statement_text']:\n",
        "    polarity, subjectivity = TextBlob(title).sentiment\n",
        "    polarities.append(polarity)\n",
        "    subjectivities.append(subjectivity)\n",
        "    avg_word_len.append(get_average_word_length(title))\n",
        "    avg_words_based_sen_len.append(get_average_word_based_sentence_length(title))\n",
        "    avg_chars_based_sen_len.append(get_average_chars_based_sentence_length(title))\n",
        "    pun_count.append(get_punctuations_count(title))\n",
        "  new_dataset = dataset[['preprocessed_statement_text']]\n",
        "  new_dataset['polarities'] = polarities\n",
        "  new_dataset['subjectivities'] = subjectivities\n",
        "  new_dataset['avg_word_len'] = avg_word_len\n",
        "  new_dataset['avg_words_based_sen_len'] = avg_words_based_sen_len\n",
        "  new_dataset['avg_chars_based_sen_len'] = avg_chars_based_sen_len\n",
        "  new_dataset['pun_count'] = pun_count\n",
        "  return new_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiyB-jT-wBMR"
      },
      "source": [
        "def create_tf_on_training(politifact_amalgamated_dataset):\n",
        "\n",
        "  print(politifact_amalgamated_dataset.columns)\n",
        "  tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_vectorizer = TfidfVectorizer()\n",
        "  sparse_matrix = tfidf_vectorizer.fit_transform(politifact_amalgamated_dataset['statement'])\n",
        "\n",
        "  doc_term_matrix = sparse_matrix.todense()\n",
        "  df = pd.DataFrame(doc_term_matrix, \n",
        "                    columns=tfidf_vectorizer.get_feature_names(), \n",
        "                    index=politifact_amalgamated_dataset['statement'])\n",
        "  return tfidf_vectorizer, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FM6OIEOwKRr"
      },
      "source": [
        "politifact_amalgamated_dataset = load_amalgamated_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIXO-T0PwIHY"
      },
      "source": [
        "target_levels = politifact_amalgamated_dataset['target_level'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIx_TkVAwLy5"
      },
      "source": [
        "def predict_credibility_and_reliability(newsFeed, model, f):\n",
        "  y_pred = []\n",
        "  if f == 1:\n",
        "    politifact_amalgamated_dataset = load_amalgamated_dataset()\n",
        "    tf_idf, df = create_tf_on_training(politifact_amalgamated_dataset)\n",
        "    stream_data = predict_mf_1_cred_of_author(tf_idf, newsFeed, politifact_amalgamated_dataset, df)\n",
        "    test_features = stream_data[['true', 'mostly_true','half_true','barely_true','false','pants_fire','total_news','credibility']]\n",
        "    # y_pred = model.predict_proba(test_features.values)\n",
        "    y_pred = model.predict_proba(test_features.values)\n",
        "  elif f == 2:\n",
        "    stream_data = predict_mf_2_content_quality(newsFeed, 'preprocessed_statement_text')\n",
        "    test_features = stream_data[['flesh_scores','smog_indexes','flesch_kincaid_grades','automated_readability_indexes','dale_chall_readability_scores','fernandez_huertas']]\n",
        "    # print(test_features.columns)\n",
        "    # y_pred = model.predict_proba(test_features)\n",
        "    y_pred = model.predict_proba(test_features)\n",
        "  elif f == 3:\n",
        "    stream_data = predict_mf_3_subjectivity(newsFeed)\n",
        "    test_features = stream_data.drop(['preprocessed_statement_text'],axis=1)\n",
        "    # y_pred = model.predict_proba(test_features.values)\n",
        "    y_pred = model.predict_proba(test_features.values)\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrDrYL_3wNZ1"
      },
      "source": [
        "def f_credibility_and_relability_ensembling(stream_data):\n",
        "\n",
        "  m1_data = read_from_drive('https://drive.google.com/file/d/1-2QHkqBRcKSGl_4ivhE0R6PkvIvBJ3LU/view?usp=sharing')\n",
        "  cred_of_author_model = cPickle.loads(m1_data.getvalue())\n",
        "\n",
        "  m1_data = read_from_drive('https://drive.google.com/file/d/1-BNeYIrEE7hLj62uZ8cxSBg4F4609TFo/view?usp=sharing')\n",
        "  content_quality_model = cPickle.loads(m1_data.getvalue())\n",
        "\n",
        "  m1_data = read_from_drive('https://drive.google.com/file/d/1-03SrbJR4n6KBMaMwFIZeMsd8q2b9omB/view?usp=sharing')\n",
        "  subjectivity_model = cPickle.loads(m1_data.getvalue())\n",
        "\n",
        "\n",
        "  mf_y_pred_1 = predict_credibility_and_reliability(stream_data, cred_of_author_model, 1)\n",
        "  mf_y_pred_2 = predict_credibility_and_reliability(stream_data, content_quality_model, 2)\n",
        "  mf_y_pred_3 = predict_credibility_and_reliability(stream_data, subjectivity_model, 3)\n",
        "  #Weighted Ensembling Of MicroFactor Models\n",
        "  accuracy = [0.45, 0.24, 0.44]\n",
        "  weights = [accuracy[0]/sum(accuracy), accuracy[1]/sum(accuracy), accuracy[2]/sum(accuracy)]\n",
        "  final_pred = (mf_y_pred_1*weights[0] + mf_y_pred_2*weights[1] + mf_y_pred_3*weights[2])\n",
        "  return final_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47_4kOT9wPMu"
      },
      "source": [
        "random_news_items = get_random_news_items(10)\n",
        "final_pred = f_credibility_and_relability_ensembling(random_news_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x4HnFNBwRaH"
      },
      "source": [
        "## Long term utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTXaaOQewVZq"
      },
      "source": [
        "def dataset_preprocessing(data):\n",
        "  # news_author = news_author_dataset()\n",
        "  data = data[data['target'].isin(['true','mostly-true','half-true','barely-true', 'mostly-false','false','pants-fire'])]\n",
        "  target_class = []\n",
        "  target_class_dict = {'true': 0, 'mostly-true': 1, 'half-true': 2, 'barely-true': 3, 'mostly-false': 3, 'false': 4, 'pants-fire': 5}\n",
        "  for i in data['target']:\n",
        "    target_class.append(target_class_dict[i])\n",
        "  data['target_class'] = target_class\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qyid6kpwXl7"
      },
      "source": [
        "def combine(news_author, news_source):\n",
        "  true = []\n",
        "  mostly_true = []\n",
        "  barely_true = []\n",
        "  half_true = []\n",
        "  false = []\n",
        "  pants_fire = []\n",
        "  total_news = []\n",
        "  credibility = []\n",
        "  for i in news_author['source']:\n",
        "    value = news_source.index[news_source['source'] == i].tolist()\n",
        "    if len(value) > 0:\n",
        "      value = value[0]\n",
        "      true.append(news_source['true'][value])\n",
        "      mostly_true.append(news_source['mostly_true'][value])\n",
        "      half_true.append(news_source['half_true'][value])\n",
        "      barely_true.append(news_source['mostly_false'][value])\n",
        "      false.append(news_source['false'][value])\n",
        "      pants_fire.append(news_source['pants_on_fire'][value])\n",
        "      total_news.append(news_source['total_news'][value])\n",
        "      credibility.append(news_source['credibility'][value])\n",
        "    else:\n",
        "      true.append(0)\n",
        "      mostly_true.append(0)\n",
        "      half_true.append(0)\n",
        "      barely_true.append(0)\n",
        "      false.append(0)\n",
        "      pants_fire.append(0)\n",
        "      total_news.append(0)\n",
        "      credibility.append(0)\n",
        "  news_author['true'] = true\n",
        "  news_author['mostly_true'] = mostly_true\n",
        "  news_author['half_true'] = half_true\n",
        "  news_author['barely_true'] = barely_true\n",
        "  news_author['false'] = false\n",
        "  news_author['pants_on_fire'] = pants_fire\n",
        "  news_author['total_true'] = news_author['true'] + news_author['mostly_true'] + news_author['half_true']\n",
        "  news_author['total_false'] = news_author['false'] + news_author['barely_true'] + news_author['pants_on_fire']\n",
        "  news_author['total_news'] = total_news\n",
        "  news_author['credibility'] = credibility\n",
        "  return news_author"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqDxKZx3wZlO"
      },
      "source": [
        "def generate_source_data(data):\n",
        "\n",
        "  true_count = 0\n",
        "  mostly_true_count =0\n",
        "  half_true_count=0\n",
        "  barely_true_count=0\n",
        "  mostly_false_count=0\n",
        "  false_count=0\n",
        "  pants_fire_count = 0\n",
        "  total_count=0\n",
        "\n",
        "  sources = ['Nur Ibrahim', 'Jordan Liles', 'Bethania Palma', 'Jessica Lee',\n",
        "        'Alex Kasprak', 'Dan MacGuill', 'Madison Dapcevich', 'Dan Evon',\n",
        "        'David Mikkelson']\n",
        "  true_list = []\n",
        "  mostly_true_list = []\n",
        "  half_true_list = []\n",
        "  barely_true_list = []\n",
        "  mostly_false_list = []\n",
        "  false_list = []\n",
        "  pants_fire_list = []\n",
        "  total_list = []\n",
        "  credibility_list = []\n",
        "\n",
        "  for src in sources:\n",
        "    new_rss_data = data[data[\"source\"] == src]\n",
        "    new_rss_data.reset_index(inplace = True)\n",
        "    for i in range(len(new_rss_data)):\n",
        "      if (new_rss_data['target'][i]=='true'):\n",
        "        true_count += 1\n",
        "      elif (new_rss_data['target'][i]=='mostly-true'):\n",
        "        mostly_true_count += 1\n",
        "      elif (new_rss_data['target'][i]=='half-true'):\n",
        "        half_true_count += 1\n",
        "      elif (new_rss_data['target'][i]=='barely-true'):\n",
        "         barely_true_count += 1\n",
        "      elif (new_rss_data['target'][i]=='mostly-false'):\n",
        "        mostly_false_count += 1\n",
        "      elif (new_rss_data['target'][i]=='false'):\n",
        "        false_count += 1\n",
        "      elif (new_rss_data['target'][i]=='pants-fire'):\n",
        "        pants_fire_count += 1\n",
        "    total_count = true_count + mostly_true_count + half_true_count + barely_true_count + mostly_false_count +  false_count + pants_fire_count\n",
        "    true_list.append(true_count)\n",
        "    mostly_true_list.append(mostly_true_count)\n",
        "    half_true_list.append(half_true_count)\n",
        "    barely_true_list.append(barely_true_count)\n",
        "    mostly_false_list.append(mostly_false_count)\n",
        "    false_list.append(false_count)\n",
        "    pants_fire_list.append(pants_fire_count)\n",
        "    total_list.append(total_count)\n",
        "    if (total_count > 0):\n",
        "      percent = [true_count/total_count, mostly_true_count/total_count, half_true_count/total_count, barely_true_count/total_count, \n",
        "                 mostly_false_count/total_count, false_count/total_count, pants_fire_count/total_count]\n",
        "      max_value = max(percent)\n",
        "      credibility_list.append(percent.index(max_value)+1)\n",
        "    else:\n",
        "      credibility_list.append(0)\n",
        "\n",
        "  #new data source\n",
        "  rss_data_new = pd.DataFrame(columns = ['source', 'true' ,'mostly_true', 'half_true', 'barely_true' , 'mostly_false', 'false', 'pants_on_fire','total_news', 'credibility']) \n",
        "  rss_data_new['source'] = sources\n",
        "  rss_data_new['true'] = true_list\n",
        "  rss_data_new['mostly_true'] = mostly_true_list\n",
        "  rss_data_new['half_true'] = half_true_list\n",
        "  rss_data_new['barely_true'] = barely_true_list\n",
        "  rss_data_new['mostly_false'] = mostly_false_list\n",
        "  rss_data_new['false'] = false_list\n",
        "  rss_data_new['pants_on_fire'] = pants_fire_list\n",
        "  rss_data_new['total_news'] = total_list\n",
        "  rss_data_new['credibility'] = credibility_list\n",
        "\n",
        "  return rss_data_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uuWkEi-wbGi"
      },
      "source": [
        "def get_reputation_score(total_true, total_news): # return between 0 and 1, being 0 = Reputable,  1 = Non-reputable\n",
        "  try:\n",
        "      true_percent = abs(total_true/total_news) * 100\n",
        "  except ZeroDivisionError:\n",
        "      true_percent = 0\n",
        "  if (true_percent >= 50):\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El95s9hkwcpN"
      },
      "source": [
        "def get_credibility_score(data):\n",
        "  credibility_score = []\n",
        "  cred_mean = data['credibility'].mean()\n",
        "  for index, row in data.iterrows():\n",
        "    if (row['credibility'] >= cred_mean):\n",
        "      credibility_score.append(0) # 0 = Credible,  1 = Non-credible\n",
        "    else:\n",
        "      credibility_score.append(1)\n",
        "  return credibility_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9rFUQ3XweVH"
      },
      "source": [
        "def simplify_venue_label(input_label):  \n",
        "  true_labels = ['news','interview','television','show', 'speech', 'reporters', 'debate', 'newsletter', 'press', \n",
        "               'CNN', 'ABC', 'CBS', 'video', 'conference', 'official', 'book']\n",
        "  false_labels = ['website', 'tweet', 'mail', 'e-mail', 'mailer', 'web', 'site', 'meme', 'comic', 'advertisement', 'ad', 'blog', 'flier', \n",
        "                'letter', 'social', 'tweets', 'internet','facebook', 'message', 'campaign', 'post', 'handout', 'leaflet' ]\n",
        "  words = input_label.lower().split(\" \")\n",
        "  for s in words:\n",
        "    if s in true_labels:\n",
        "      return 0\n",
        "    elif s in false_labels:\n",
        "      return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjXvWp9Wwf9_"
      },
      "source": [
        "def compute_repuation(data):\n",
        "  reput_score = []\n",
        "  for index, row in data.iterrows():\n",
        "    rs = get_reputation_score(row['total_true'],row['total_news'])\n",
        "    reput_score.append(rs)\n",
        "\n",
        "  data['reputation_score'] = reput_score\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kncc7EFRwhiw"
      },
      "source": [
        "def compute_credibility(data):\n",
        "  data['credibility_score'] = get_credibility_score(data)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAzBwfs-witO"
      },
      "source": [
        "def compute_authenticity(data):\n",
        "  data['authenticity_score'] = data.apply(lambda row: simplify_venue_label(str(row['context'])), axis=1)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPjDDwxAwkH-"
      },
      "source": [
        "def predict_long_term_utility(data, model, f):\n",
        "  y_pred = []\n",
        "  if f == 1:\n",
        "    stream_data = compute_repuation(data)\n",
        "    test_features = stream_data[['total_true','total_false','total_news','reputation_score']]\n",
        "    y_pred = model.predict_proba(test_features.values)\n",
        "  elif f == 2:\n",
        "    stream_data = compute_credibility(data)\n",
        "    test_features = stream_data[['total_true','total_false','total_news','credibility_score']]\n",
        "    y_pred = model.predict_proba(test_features.values)\n",
        "  elif f == 3:\n",
        "    stream_data = compute_authenticity(data)\n",
        "    test_features = stream_data[['total_true','total_false','total_news','authenticity_score']]\n",
        "    y_pred = model.predict_proba(test_features.values)\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDbnRo-hwlyG"
      },
      "source": [
        "def f_long_term_utility_ensembling(stream_data):\n",
        "\n",
        "  rss_data_author = stream_data #dataset_preprocessing(stream_data)\n",
        "  \n",
        "  news_author_amalgamated = read_csv_from_drive(\"https://drive.google.com/file/d/1-J33YfIT8nuJiwMPw4e0n7uOJn1Hdcxc/view?usp=sharing\")\n",
        "  index=np.random.choice(news_author_amalgamated['context'].nunique(), size=(rss_data_author.shape[0]))\n",
        "  context_list=[]\n",
        "  for i in index:\n",
        "    context_list.append(news_author_amalgamated['context'][i])\n",
        "\n",
        "  rss_data_author['context']=context_list\n",
        "  rss_data_source = generate_source_data(rss_data_author)\n",
        "  rss_test_data = combine(rss_data_author, rss_data_source)\n",
        "\n",
        "  m1_data = read_from_drive('https://drive.google.com/file/d/1-LPitQ6AbS0M-eq3RDr2s3LgD6847qsv/view?usp=sharing')\n",
        "  reputation_model = cPickle.loads(m1_data.getvalue())\n",
        "\n",
        "  m1_data = read_from_drive('https://drive.google.com/file/d/1-PY_qbeK3j9SvYAFXMzTl6_u900FYUgL/view?usp=sharing')\n",
        "  credibility_model = cPickle.loads(m1_data.getvalue())\n",
        "\n",
        "  m1_data = read_from_drive('https://drive.google.com/file/d/1-QHh4d4HAN8rIJfekjrfu4jlDb85e2Fj/view?usp=sharing')\n",
        "  authenticity_model = cPickle.loads(m1_data.getvalue())\n",
        "\n",
        "  mf_y_pred_1 = predict_long_term_utility(rss_test_data, reputation_model, 1)\n",
        "  mf_y_pred_2 = predict_long_term_utility(rss_test_data, credibility_model, 2)\n",
        "  mf_y_pred_3 = predict_long_term_utility(rss_test_data, authenticity_model, 3)\n",
        "\n",
        "  #Weighted Ensembling Of MicroFactor Models\n",
        "  final_pred = (mf_y_pred_1*0.5 + mf_y_pred_2*0.2 + mf_y_pred_3*0.3)\n",
        "  return final_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P0u4CLJwnG2"
      },
      "source": [
        "## data divers ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUKQ2xYhwrXr"
      },
      "source": [
        "def data_divers_ensemble(data):\n",
        "  lta_pred = f_long_term_utility_ensembling(data)\n",
        "  ma_pred = ma_prediction(data)\n",
        "  cr_pred = f_credibility_and_relability_ensembling(data)\n",
        "  return lta_pred*0.2 + ma_pred*0.1 + cr_pred*0.7"
      ],
      "execution_count": null,

      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EHyXA9Zd-CM"
      },
      "source": [
        "# 3.0. Automated Inference Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnQh4rgCvSK4"
      },
      "source": [
        "## 3.1. Helper: Pick a random news item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sspSi0vxeQ04"
      },
      "source": [
        "def get_random_news_items(num_items):\n",
        "  random_news_items = df_test_headlines.sample(n=num_items)\n",
        "  return random_news_items"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ8H3Y9ceDhM"
      },
      "source": [
        "## 3.2. Helper:Print prediction of news item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXPuqpUyfGoN"
      },
      "source": [
        "def print_prediction(reading):\n",
        "  if reading > 0.9:\n",
        "    print (\"This news headline is: Pants on Fire\")\n",
        "  elif reading > 0.7 and reading < 0.9:\n",
        "    print (\"This news headline is: Somewhat False\")\n",
        "  elif reading > 0.5 and reading < 0.7:\n",
        "    print (\"This news headline is: Mostly False\")\n",
        "  elif reading > 0.3 and reading < 0.5:\n",
        "    print (\"This news headline is: Half True\")\n",
        "  elif reading > 0.1 and reading < 0.3:\n",
        "    print (\"This news headline is: Mostly True\")\n",
        "  elif reading < 0.1:\n",
        "    print (\"True\")  "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqk1SUgEg_5k"
      },
      "source": [
        "## 3.3. Helper: Run automated pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1-VQtbUo69_"
      },
      "source": [
        "def run_automated_inference_pipeline(num_items):\n",
        "  X_headline = 'preprocessed_statement_text'\n",
        "  X_body = 'preprocessed_body'\n",
        "  random_news_items = get_random_news_items(num_items)\n",
        "\n",
        "  i = 0\n",
        "  while ( i < num_items):\n",
        "    news = random_news_items.sample(1)\n",
        "    print('\\nRunning [false-o-meter] on - %s ' % (news['text']))\n",
        "    reading = get_false_o_meter_reading(news, news.index[0], X_headline, X_body)\n",
        "    print('[false-o-meter] reading is %f ' %(reading))\n",
        "    print_prediction(reading)\n",
        "    i = i + 1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRSFK3w0hUX7"
      },
      "source": [
        "## 3.4. Invoke automated pipeline on 20 random news items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elezXf39cBuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bfc542-eebf-4c55-d844-3847cc056b14"
      },
      "source": [
        "num_news = 20\n",
        "reading = run_automated_inference_pipeline(num_news)"
=======
        "id": "elezXf39cBuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210fb337-48fe-4234-99cb-a3785b11efaa"
      },
      "source": [
        "num_news = 20\n",
        "reading = run_automated_inference_pipeline(num_news)"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
<<<<<<< HEAD
            "Running [false-o-meter] on - 177    Fashion Notes: The 9 Best and Worst Dressed Ac...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.971518 \n",
            "Stance [false-o-meter] reading is (agree: 0.759230, disagree: 0.000043, neutral: 0.240727)\n",
            "Political Bias [false-o-meter] reading is 0.295789 \n",
            "Title-Body incongruence [false-o-meter] reading is 1.400000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Distilled Intent [false-o-meter] reading is 0.000000 \n",
            "Spam score is 0.461798\n",
            "Ensembled [false-o-meter] reading is 0.522364 \n",
            "[false-o-meter] reading is 0.522364 \n",
            "This news headline is: Mostly False\n",
            "\n",
            "Running [false-o-meter] on - 236    VA's implant tests could help paralyzed vetera...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.502400 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.686641 \n",
            "Stance [false-o-meter] reading is (agree: 0.000701, disagree: 0.003051, neutral: 0.996249)\n",
            "Political Bias [false-o-meter] reading is 0.341893 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.552000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Distilled Intent [false-o-meter] reading is 0.000000 \n",
            "Spam score is 0.453683\n",
            "Ensembled [false-o-meter] reading is 0.428746 \n",
            "[false-o-meter] reading is 0.428746 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 82    Oscars red carpet fashion 2021: A glimpse of n...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.391180 \n",
            "Stance [false-o-meter] reading is (agree: 0.995968, disagree: 0.003338, neutral: 0.000694)\n",
            "Political Bias [false-o-meter] reading is 0.272923 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.460000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Distilled Intent [false-o-meter] reading is 0.000000 \n",
            "Spam score is 0.420441\n",
            "Ensembled [false-o-meter] reading is 0.367160 \n",
            "[false-o-meter] reading is 0.367160 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 82    Oscars red carpet fashion 2021: A glimpse of n...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.391180 \n",
            "Stance [false-o-meter] reading is (agree: 0.995968, disagree: 0.003338, neutral: 0.000694)\n",
            "Political Bias [false-o-meter] reading is 0.272923 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.460000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Distilled Intent [false-o-meter] reading is 0.000000 \n",
            "Spam score is 0.420441\n",
            "Ensembled [false-o-meter] reading is 0.367160 \n",
            "[false-o-meter] reading is 0.367160 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 126    Nolte: Woketard Oscar Ratings Plummet 58%, Fir...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.414389 \n"
=======
            "Running [false-o-meter] on - 131    GRAPHIC: Armored Cartel Shootout in Mexico Kil...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.466295 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.006669 \n",
            "Stance [false-o-meter] reading is (agree: 0.000000, disagree: 0.000024, neutral: 0.999976)\n",
            "Political Bias [false-o-meter] reading is 0.220298 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.432000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.305871 \n",
            "[false-o-meter] reading is 0.305871 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 81    Fully vaccinated Americans will be able to vac...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.198846 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.009741 \n",
            "Stance [false-o-meter] reading is (agree: 0.992321, disagree: 0.000004, neutral: 0.007675)\n",
            "Political Bias [false-o-meter] reading is 0.239462 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.442000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.290552 \n",
            "[false-o-meter] reading is 0.290552 \n",
            "This news headline is: Mostly True\n",
            "\n",
            "Running [false-o-meter] on - 94    Making sense of the math behind carbon emissio...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.336898 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.236157 \n",
            "Stance [false-o-meter] reading is (agree: 0.000000, disagree: 0.000195, neutral: 0.999804)\n",
            "Political Bias [false-o-meter] reading is 0.234023 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.418000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.341813 \n",
            "[false-o-meter] reading is 0.341813 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 178    WATCH: Cops Mock LeBron over ‘YOU’RE NEXT’ Tweet\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.865926 \n",
            "Stance [false-o-meter] reading is (agree: 0.002318, disagree: 0.011486, neutral: 0.986197)\n",
            "Political Bias [false-o-meter] reading is 0.227388 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.562000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.437861 \n",
            "[false-o-meter] reading is 0.437861 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 180    Oscars: China Censors Social Media Celebration...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.499906 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.018484 \n",
            "Stance [false-o-meter] reading is (agree: 0.999999, disagree: 0.000001, neutral: 0.000000)\n",
            "Political Bias [false-o-meter] reading is 0.203672 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.556000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.314078 \n",
            "[false-o-meter] reading is 0.314078 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 240    Beavers reportedly knock out cell phone and in...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.131691 \n",
            "Stance [false-o-meter] reading is (agree: 0.017785, disagree: 0.324004, neutral: 0.658211)\n",
            "Political Bias [false-o-meter] reading is 0.210487 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.798000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.352407 \n",
            "[false-o-meter] reading is 0.352407 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 142    Uber Driver Crashes into Canal – Customer Stil...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.658591 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.135993 \n",
            "Stance [false-o-meter] reading is (agree: 0.998196, disagree: 0.001782, neutral: 0.000022)\n",
            "Political Bias [false-o-meter] reading is 0.222232 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.406000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.338694 \n",
            "[false-o-meter] reading is 0.338694 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 94    Making sense of the math behind carbon emissio...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.336898 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.236157 \n",
            "Stance [false-o-meter] reading is (agree: 0.000000, disagree: 0.000195, neutral: 0.999804)\n",
            "Political Bias [false-o-meter] reading is 0.234023 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.418000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.341813 \n",
            "[false-o-meter] reading is 0.341813 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 74    In pictures: The stars are out for the Oscars\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.875174 \n",
            "Stance [false-o-meter] reading is (agree: 0.968334, disagree: 0.031648, neutral: 0.000019)\n",
            "Political Bias [false-o-meter] reading is 0.263368 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.848000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.461005 \n",
            "[false-o-meter] reading is 0.461005 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 24    EU expands on 'coordinated approach' to reopen...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.007748 \n",
            "Stance [false-o-meter] reading is (agree: 0.336279, disagree: 0.000002, neutral: 0.663720)\n",
            "Political Bias [false-o-meter] reading is 0.226436 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.938000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.352863 \n",
            "[false-o-meter] reading is 0.352863 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 74    In pictures: The stars are out for the Oscars\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.875174 \n",
            "Stance [false-o-meter] reading is (agree: 0.968334, disagree: 0.031648, neutral: 0.000019)\n",
            "Political Bias [false-o-meter] reading is 0.263368 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.848000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.461005 \n",
            "[false-o-meter] reading is 0.461005 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 184    Gunmen Raid Home of Bishop-Elect in South Suda...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.473688 \n",
            "Sensationalism [false-o-meter] reading is 0.453326 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.010705 \n",
            "Stance [false-o-meter] reading is (agree: 0.192769, disagree: 0.000093, neutral: 0.807139)\n",
            "Political Bias [false-o-meter] reading is 0.202564 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.406000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.317267 \n",
            "[false-o-meter] reading is 0.317267 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 127    New Era of Remote Workers Spawns Domestic Migr...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.198762 \n",
            "Stance [false-o-meter] reading is (agree: 0.967317, disagree: 0.027027, neutral: 0.005657)\n",
            "Political Bias [false-o-meter] reading is 0.155447 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.522000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.328827 \n",
            "[false-o-meter] reading is 0.328827 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 180    Oscars: China Censors Social Media Celebration...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.499906 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.018484 \n",
            "Stance [false-o-meter] reading is (agree: 0.999999, disagree: 0.000001, neutral: 0.000000)\n",
            "Political Bias [false-o-meter] reading is 0.203672 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.556000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.314078 \n",
            "[false-o-meter] reading is 0.314078 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 74    In pictures: The stars are out for the Oscars\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.875174 \n",
            "Stance [false-o-meter] reading is (agree: 0.968334, disagree: 0.031648, neutral: 0.000019)\n",
            "Political Bias [false-o-meter] reading is 0.263368 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.848000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.461005 \n",
            "[false-o-meter] reading is 0.461005 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 178    WATCH: Cops Mock LeBron over ‘YOU’RE NEXT’ Tweet\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.865926 \n",
            "Stance [false-o-meter] reading is (agree: 0.002318, disagree: 0.011486, neutral: 0.986197)\n",
            "Political Bias [false-o-meter] reading is 0.227388 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.562000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.437861 \n",
            "[false-o-meter] reading is 0.437861 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 92    Texas congressman 'hopeful and confident' afte...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.060958 \n",
            "Stance [false-o-meter] reading is (agree: 0.000639, disagree: 0.000054, neutral: 0.999308)\n",
            "Political Bias [false-o-meter] reading is 0.375413 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.430000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.329661 \n",
            "[false-o-meter] reading is 0.329661 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 184    Gunmen Raid Home of Bishop-Elect in South Suda...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.473688 \n",
            "Sensationalism [false-o-meter] reading is 0.453326 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.010705 \n",
            "Stance [false-o-meter] reading is (agree: 0.192769, disagree: 0.000093, neutral: 0.807139)\n",
            "Political Bias [false-o-meter] reading is 0.202564 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.406000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.317267 \n",
            "[false-o-meter] reading is 0.317267 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 178    WATCH: Cops Mock LeBron over ‘YOU’RE NEXT’ Tweet\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.483895 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.865926 \n",
            "Stance [false-o-meter] reading is (agree: 0.002318, disagree: 0.011486, neutral: 0.986197)\n",
            "Political Bias [false-o-meter] reading is 0.227388 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.562000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.437861 \n",
            "[false-o-meter] reading is 0.437861 \n",
            "This news headline is: Half True\n",
            "\n",
            "Running [false-o-meter] on - 180    Oscars: China Censors Social Media Celebration...\n",
            "Name: text, dtype: object \n",
            "Sentiment [false-o-meter] reading is 0.499906 \n",
            "Sensationalism [false-o-meter] reading is 0.315909 \n",
            "Distilled Clickbait [false-o-meter] reading is 0.018484 \n",
            "Stance [false-o-meter] reading is (agree: 0.999999, disagree: 0.000001, neutral: 0.000000)\n",
            "Political Bias [false-o-meter] reading is 0.203672 \n",
            "Title-Body incongruence [false-o-meter] reading is 0.556000 \n",
            "Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n",
            "Ensembled [false-o-meter] reading is 0.314078 \n",
            "[false-o-meter] reading is 0.314078 \n",
            "This news headline is: Half True\n"
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
          ],
          "name": "stdout"
        }
      ]
    }
  ]
<<<<<<< HEAD

}

=======
}
>>>>>>> f31fcc01f84b88263cbe0bd622865d2c91201638
